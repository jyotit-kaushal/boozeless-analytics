{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all necessary imports\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the dataset from json\n",
    "df= pd.read_json('/Users/jyotit-kaushal/github/boozeless-analytics/data/singapore_geo_dataset.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a ranking system governed by rating and number of reviews using bayesian probability\n",
    "df_temp1= df[df['review_count']>=100]\n",
    "r= df_temp1['average_rating'].mean()\n",
    "w= (df['review_count'].mean())/5\n",
    "\n",
    "bayesian_weighted_rating= ((r*w)+(df['average_rating']*df['review_count']))/(w+df['review_count'])\n",
    "df['bayesian_weighted_rating']= bayesian_weighted_rating\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns= ['region', 'neighborhood', 'price_point_bucket', 'platform_category', 'venue_segment']\n",
    "\n",
    "\n",
    "df_temp2= df.copy()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df_temp2[col] = encoder.fit_transform(df_temp2[col])\n",
    "\n",
    "train_data = df_temp2.dropna(subset=['bayesian_weighted_rating'])\n",
    "test_data = df_temp2[df_temp2['bayesian_weighted_rating'].isna()]\n",
    "\n",
    "X_train = train_data[categorical_columns]\n",
    "y_train = train_data['bayesian_weighted_rating']\n",
    "X_test = test_data[categorical_columns]\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_y_train= model.predict(X_train)\n",
    "r2= r2_score(y_train, pred_y_train)\n",
    "\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "mse = mean_squared_error(y_train, pred_y_train)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "missing_review_predictions = model.predict(X_test)\n",
    "\n",
    "df.loc[df['bayesian_weighted_rating'].isna(), 'bayesian_weighted_rating'] = missing_review_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "busy_during_nighttime = []\n",
    "\n",
    "for busy_time_dict in df['busy_times']:\n",
    "    if busy_time_dict:\n",
    "        times=[]\n",
    "        for day, set_times in busy_time_dict.items():\n",
    "            midnight= list(busy_time_dict[day].values())[:1]\n",
    "            nighttime= list(busy_time_dict[day].values())[-7:]\n",
    "            times.extend(midnight)\n",
    "            times.extend(nighttime)\n",
    "\n",
    "        if((sum(times)/(8*6))>40):\n",
    "            busy_during_nighttime.append(\"Yes\")\n",
    "        else:\n",
    "            busy_during_nighttime.append(\"No\")\n",
    "    else:\n",
    "        busy_during_nighttime.append(None)\n",
    "            \n",
    "print(busy_during_nighttime)\n",
    "\n",
    "df['busy_during_nighttime']=busy_during_nighttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp3 = df.copy()\n",
    "\n",
    "atmosphere = []\n",
    "crowd = []\n",
    "dining_options = []\n",
    "happy_hour = []\n",
    "highlights = []\n",
    "offerings = []\n",
    "payments = []\n",
    "planning = []\n",
    "types_of_alcohol = []\n",
    "amenities_cat = []\n",
    "accessibility = []\n",
    "ordering_options = []\n",
    "\n",
    "for amenities in df['venue_amenities']:\n",
    "    if amenities:\n",
    "        if 'amenities' in amenities:\n",
    "            amenities_cat.append(amenities['amenities'])\n",
    "        else:\n",
    "            amenities_cat.append(None)\n",
    "\n",
    "        if 'atmosphere' in amenities:\n",
    "            atmosphere.append(amenities['atmosphere'])\n",
    "        else:\n",
    "            atmosphere.append(None)\n",
    "        \n",
    "        if 'crowd' in amenities:\n",
    "            crowd.append(amenities['crowd'])\n",
    "        else:\n",
    "            crowd.append(None)\n",
    "            \n",
    "        if 'dining_options' in amenities:\n",
    "            dining_options.append(amenities['dining_options'])\n",
    "        else:\n",
    "            dining_options.append(None)\n",
    "\n",
    "        if 'ordering_options' in amenities:\n",
    "            ordering_options.append(amenities['ordering_options'])\n",
    "        else:\n",
    "            ordering_options.append(None)\n",
    "            \n",
    "        if 'happy_hour' in amenities:\n",
    "            happy_hour.append(amenities['happy_hour'])\n",
    "        else:\n",
    "            happy_hour.append(None)\n",
    "            \n",
    "        if 'highlights' in amenities:\n",
    "            highlights.append(amenities['highlights'])\n",
    "        else:\n",
    "            highlights.append(None)\n",
    "            \n",
    "        if 'offerings' in amenities:\n",
    "            offerings.append(amenities['offerings'])\n",
    "        else:\n",
    "            offerings.append(None)\n",
    "            \n",
    "        if 'payments' in amenities:\n",
    "            payments.append(amenities['payments'])\n",
    "        else:\n",
    "            payments.append(None)\n",
    "            \n",
    "        if 'planning' in amenities:\n",
    "            planning.append(amenities['planning'])\n",
    "        else:\n",
    "            planning.append(None)\n",
    "            \n",
    "        if 'types_of_alcohol' in amenities:\n",
    "            types_of_alcohol.append(amenities['types_of_alcohol'])\n",
    "        else:\n",
    "            types_of_alcohol.append(None)\n",
    "\n",
    "        if 'accessability' in amenities:\n",
    "            accessibility.append(amenities['accessability'])\n",
    "        else:\n",
    "            accessibility.append(None)\n",
    "\n",
    "    else:\n",
    "        atmosphere.append(None)\n",
    "        crowd.append(None)\n",
    "        dining_options.append(None)\n",
    "        happy_hour.append(None)\n",
    "        highlights.append(None)\n",
    "        offerings.append(None)\n",
    "        payments.append(None)\n",
    "        planning.append(None)\n",
    "        types_of_alcohol.append(None)\n",
    "        amenities_cat.append(None)\n",
    "        ordering_options.append(None)\n",
    "        accessibility.append(None)\n",
    "\n",
    "df['atmosphere'] = atmosphere\n",
    "df['crowd'] = crowd\n",
    "df['dining_options'] = dining_options\n",
    "df['happy_hour'] = happy_hour\n",
    "df['highlights'] = highlights\n",
    "df['offerings'] = offerings\n",
    "df['payments'] = payments\n",
    "df['planning'] = planning\n",
    "df['types_of_alcohol'] = types_of_alcohol\n",
    "df['ordering_options'] = ordering_options\n",
    "df['amenities_cat'] = amenities_cat\n",
    "df['accessibility'] = accessibility\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['average_rating', 'busy_times', 'venue_amenities', 'venue_amenities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns= ['region', 'neighborhood', 'platform_category', 'venue_segment', 'bayesian_weighted_rating']\n",
    "\n",
    "\n",
    "df_temp4= df.copy()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    df_temp4[col] = encoder.fit_transform(df_temp4[col])\n",
    "\n",
    "df_temp4['price_point_bucket']= encoder.fit_transform(df_temp4['price_point_bucket'])\n",
    "\n",
    "df_temp4.loc[df_temp4['price_point_bucket'] == 4, 'price_point_bucket'] = None\n",
    "\n",
    "\n",
    "train_data = df_temp4.dropna(subset=['price_point_bucket'])\n",
    "test_data = df_temp4[df_temp4['price_point_bucket'].isna()]\n",
    "\n",
    "X_train = train_data[categorical_columns]\n",
    "y_train = train_data['price_point_bucket']\n",
    "X_test = test_data[categorical_columns]\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "pred_y_train= model.predict(X_train)\n",
    "r2= r2_score(y_train, pred_y_train)\n",
    "\n",
    "print(\"R2 Score:\", r2)\n",
    "\n",
    "mse = mean_squared_error(y_train, pred_y_train)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "missing_pricepoint_predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "def change_to_symbols(lst):\n",
    "    symbols = {0: '$', 1: '$$', 2: '$$$', 3: '$$$$'}\n",
    "    result = []\n",
    "\n",
    "    for value in lst:\n",
    "        if value in symbols:\n",
    "            result.append(symbols[value])\n",
    "        else:\n",
    "            result.append(value)\n",
    "\n",
    "    return result\n",
    "\n",
    "missing_pricepoint_predictions= change_to_symbols(missing_pricepoint_predictions)\n",
    "\n",
    "df.loc[df['price_point_bucket'].isna(), 'price_point_bucket'] = missing_pricepoint_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_sample']= df['review_sample'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"/Users/jyotit-kaushal/github/boozeless-analytics/data/singapore_processed_dataset.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table_nightbusy = pd.pivot_table(df, \n",
    "                            index='busy_during_nighttime', \n",
    "                            aggfunc='size', \n",
    "                            fill_value=0)\n",
    "\n",
    "print(pivot_table_nightbusy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table for price_point_bucket\n",
    "pivot_table_pricepoint = pd.pivot_table(df, \n",
    "                            index='price_point_bucket', \n",
    "                            aggfunc='size', \n",
    "                            fill_value=0)\n",
    "\n",
    "print(pivot_table_pricepoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table for venue_segment\n",
    "pivot_table_venueseg = pd.pivot_table(df, \n",
    "                            index='venue_segment', \n",
    "                            aggfunc='size', \n",
    "                            fill_value=0)\n",
    "\n",
    "print(pivot_table_venueseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table_venuesubseg = pd.pivot_table(df, \n",
    "                            index='venue_subsegment', \n",
    "                            aggfunc='size', \n",
    "                            fill_value=0)\n",
    "\n",
    "print(pivot_table_venuesubseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot table for reviews\n",
    "\n",
    "df['review_count_10000'] = df['review_count'].round(-3)\n",
    "\n",
    "pivot_table_reviewcnt = pd.pivot_table(df, \n",
    "                            index='review_count_10000', \n",
    "                            aggfunc='size', \n",
    "                            fill_value=0)\n",
    "\n",
    "print(pivot_table_reviewcnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datasci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
